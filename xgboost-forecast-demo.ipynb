{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip --disable-pip-version-check install -U pandas numpy xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip freeze | grep \"pandas=\\|numpy=\\|xgboost=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from data import passwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/image/design.png\" width=900 height=900 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "**We will build a forecast model to predict the sales of energy drinks for a retail store located in Iowa City,Iowa. We have 1 year historical data, dated back from 2021-06-01 to 2022-07-04. We will use 2021-06-01 to 2022-06-19 as training date and then predict the demand for the dates between 2022-06-20 to 2022-07-04.**\n",
    "\n",
    "**We use suggested radius of 1.76 km to search for the nearby events to this store. There are 23 venues close to this store within 1.76km radius. By running the Beam and category importance model, we learned that there are six event categories having statistical correlation to the demand which are:**\n",
    "- Sports\n",
    "- Public holidays\n",
    "- School holidays\n",
    "- Expos\n",
    "- Obervances\n",
    "- Severe weather\n",
    "- Concerts\n",
    "- Performing arts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Severe weather events with Demand Impact Patterns and Polygons\n",
    "\n",
    "* Severe Weather is one of the most impactful event categories in the world. Warnings or alerts of severe weather may lead to disruption and can have a huge influence on demand.\n",
    "* Severe weather events impact demand before and after an event. PredictHQâ€™s Demand Impact Pattern accurately captures the leading, lagging and coincident effects of a severe weather event on demand. \n",
    "* Easy to use severe weather event features in a forecast through feature API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/image/swdip.png\" width=900 height=900 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_important_results = ['public_holidays',\n",
    "                              'sports',\n",
    "                              'school_holidays',\n",
    "                              'expos',\n",
    "                              'observances',\n",
    "                              'sw',\n",
    "                              'concerts',\n",
    "                              'performing_arts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "FEATURES_API_URL = \"https://api.predicthq.com/v1/features\"\n",
    "ACCESS_TOKEN = passwords.ACCESS_TOKEN\n",
    "SEVERE_WEATHER_FEATURES = {\n",
    "    \"phq_impact_severe_weather_air_quality_retail\",\n",
    "    \"phq_impact_severe_weather_blizzard_retail\",\n",
    "    \"phq_impact_severe_weather_cold_wave_retail\",\n",
    "    \"phq_impact_severe_weather_cold_wave_snow_retail\",\n",
    "    \"phq_impact_severe_weather_cold_wave_storm_retail\",\n",
    "    \"phq_impact_severe_weather_dust_retail\",\n",
    "    \"phq_impact_severe_weather_dust_storm_retail\",\n",
    "    \"phq_impact_severe_weather_flood_retail\",\n",
    "    \"phq_impact_severe_weather_heat_wave_retail\",\n",
    "    \"phq_impact_severe_weather_hurricane_retail\",\n",
    "    \"phq_impact_severe_weather_thunderstorm_retail\",\n",
    "    \"phq_impact_severe_weather_tornado_retail\",\n",
    "    \"phq_impact_severe_weather_tropical_storm_retail\",\n",
    "}\n",
    "SCHOOL_HOLIDAYS_FEATURE = \"phq_attendance_school_holidays\"\n",
    "\n",
    "\n",
    "def get_features_api_severe_weather_events(lat, lon, start, end, rank_threshold=30):\n",
    "    start = datetime.strptime(start, DATE_FORMAT).date()\n",
    "    end = datetime.strptime(end, DATE_FORMAT).date()\n",
    "\n",
    "    print(\"Querying Features API...\")\n",
    "    result = []\n",
    "    for gte, lte in get_date_groups(start, end):\n",
    "        print(f\"{gte} -> {lte}\")\n",
    "        request_data = {\n",
    "            \"location\": {\"geo\": {\"lat\": lat, \"lon\": lon, \"radius\": \"1m\"}},\n",
    "            \"active\": {\"gte\": gte, \"lte\": lte},\n",
    "        }\n",
    "        for feature in SEVERE_WEATHER_FEATURES:\n",
    "            request_data[feature] = {\n",
    "                                    'stats': ['max'],\n",
    "                                    'phq_rank': { \n",
    "                                        'gte': rank_threshold\n",
    "                                    }\n",
    "                                }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                f\"{FEATURES_API_URL}\",\n",
    "                headers={\"Authorization\": f\"Bearer {ACCESS_TOKEN}\"},\n",
    "                json=request_data,\n",
    "            ).json()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return {}, f\"{e}\"\n",
    "\n",
    "        for day in response[\"results\"]:\n",
    "            features = {'date': day[\"date\"]}\n",
    "            features.update({f: day[f][\"stats\"][\"max\"] for f in SEVERE_WEATHER_FEATURES})\n",
    "            result.append(features)\n",
    "    return result, None\n",
    "\n",
    "\n",
    "\n",
    "def get_date_groups(start, end):\n",
    "    \"\"\"\n",
    "    Features API allows range up to 90 days, so we have to do several requests\n",
    "    \"\"\"\n",
    "    def _split_dates(s, e):\n",
    "        capacity = timedelta(days=90)\n",
    "        interval = 1 + int((e - s) / capacity)\n",
    "        for i in range(interval):\n",
    "            yield s + capacity * i\n",
    "        yield e\n",
    "\n",
    "    dates = list(_split_dates(start, end))\n",
    "    for i, (d1, d2) in enumerate(zip(dates, dates[1:])):\n",
    "        if d2 != dates[-1]:\n",
    "            d2 -= timedelta(days=1)\n",
    "        yield d1.strftime(DATE_FORMAT), d2.strftime(DATE_FORMAT)\n",
    "    \n",
    "res = get_features_api_severe_weather_events(41.6576029, -91.53717840355998, '2021-06-01', '2022-07-04',60)\n",
    "df_severe_weather_features = pd.DataFrame(res[0])\n",
    "columns_constant = [col for col in df_severe_weather_features.sum()[1:].to_dict().keys() if df_severe_weather_features[col].sum() ==0]\n",
    "df_severe_weather_features.drop(columns = columns_constant, inplace=True)\n",
    "df_severe_weather_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTENDED_FEATURES = [\n",
    "    \"phq_attendance_community\",\n",
    "    \"phq_attendance_concerts\",\n",
    "    \"phq_attendance_conferences\",\n",
    "    \"phq_attendance_expos\",\n",
    "    \"phq_attendance_festivals\",\n",
    "    \"phq_attendance_performing_arts\",\n",
    "    \"phq_attendance_sports\",\n",
    "    \"phq_attendance_school_holidays\",\n",
    "]\n",
    "HOLIDAY_FEATURES = [\n",
    "    \"phq_rank_observances\",\n",
    "    \"phq_rank_public_holidays\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_features_api_data(lat, lon, start, end, radius, rank_threshold=30):\n",
    "    start = datetime.strptime(start, DATE_FORMAT).date()\n",
    "    end = datetime.strptime(end, DATE_FORMAT).date()\n",
    "\n",
    "    print(\"Querying Features API...\")\n",
    "    result = []\n",
    "    for gte, lte in get_date_groups(start, end):\n",
    "        print(f\"{gte} -> {lte}\")\n",
    "        request_data = {\n",
    "            \"location\": {\"geo\": {\"lat\": lat, \"lon\": lon, \"radius\": f\"{radius}m\"}},\n",
    "            \"active\": {\"gte\": gte, \"lte\": lte},\n",
    "        }\n",
    "        for feature in ATTENDED_FEATURES:\n",
    "            request_data[feature] = {\n",
    "                                    'stats': ['sum'], \n",
    "                                    'phq_rank': { \n",
    "                                        'gte': rank_threshold\n",
    "                                    }\n",
    "                                }\n",
    "            \n",
    "        for feature in HOLIDAY_FEATURES:\n",
    "            request_data[feature] = True\n",
    "\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                f\"{FEATURES_API_URL}\",\n",
    "                headers={\"Authorization\": f\"Bearer {ACCESS_TOKEN}\"},\n",
    "                json=request_data,\n",
    "            ).json()\n",
    "        except Exception as e:\n",
    "            return {}, f\"{e}\"\n",
    "        \n",
    "        for day in response[\"results\"]:\n",
    "            #print(day)\n",
    "            features = {'date': day[\"date\"]}\n",
    "            features.update({f: day[f][\"stats\"][\"sum\"] for f in ATTENDED_FEATURES})\n",
    "            features.update({f: sum(day[f][\"rank_levels\"].values()) for f in HOLIDAY_FEATURES})\n",
    "            result.append(features)\n",
    "    return result, None\n",
    "\n",
    "res = get_features_api_data(41.6576029, -91.53717840355998, '2021-06-01', '2022-07-30', 1760, 30)\n",
    "df_attended_holidays = pd.DataFrame(res[0])\n",
    "columns_constant = [col for col in df_attended_holidays.columns[1:] if col.replace(\"phq_attendance_\",\"\").replace(\"phq_rank_\",\"\") not in category_important_results]\n",
    "df_attended_holidays.drop(columns = columns_constant,inplace=True)\n",
    "df_attended_holidays.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sw' in category_important_results:\n",
    "    df_event_features = df_attended_holidays.merge(df_severe_weather_features, on='date', how='left')\n",
    "else:\n",
    "    df_event_features = df_attended_holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load demand and event feature through csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demand dataset and event features\n",
    "df_demand = pd.read_csv(\"data/demand.csv\")\n",
    "#df_event_features = pd.read_csv(\"data/event_features.csv\")\n",
    "df_demand['date'] = pd.to_datetime(df_demand['date'])\n",
    "df_event_features['date'] = pd.to_datetime(df_event_features['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine event features with time trend features\n",
    "#### (3 layers: day of week, week of year, month of year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to time relevant feature\n",
    "df_event_features[['day_of_week', 'week_of_year', 'month_of_year']] = df_event_features['date'].map(lambda x: [x.day_of_week, x.weekofyear, x.month]).to_list()\n",
    "df = df_demand.merge(df_event_features, how='left', on ='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a forecast using XGBoost model based on the above features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date_test = '2022-06-20'\n",
    "feature_columns = df.columns[2:]\n",
    "demand_column = 'demand'\n",
    "\n",
    "X_train = df[df['date']<split_date_test][feature_columns]\n",
    "X_test = df[df['date']>=split_date_test][feature_columns]\n",
    "y_train = df[df['date']<split_date_test][demand_column]\n",
    "y_test = df[df['date']>=split_date_test][demand_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(X_train), len(X_test), len(y_train), len(y_test)\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=100,\n",
    "                        learning_rate = .1,\n",
    "                        max_depth = 6,\n",
    "                        random_state=42,\n",
    "                        n_jobs = -1,\n",
    "                        )\n",
    "xgb_model.fit(X_train, \n",
    "                y_train,\n",
    "                verbose=True,\n",
    "                )\n",
    "#xgb_model.save_model(f\"xgb_demand_forecasting.json\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast the next two weeks' demand starting from 2022-06-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x= df[df['date']<split_date_test]['date'],\n",
    "            y=df[df['date']<split_date_test][demand_column],\n",
    "            name = 'y_training',\n",
    "            mode=\"lines+markers\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x= df[df['date']>=split_date_test]['date'],\n",
    "            y=xgb_model.predict(X_test),\n",
    "            name = 'y_prediction',\n",
    "            mode=\"lines+markers\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x= df[df['date']>=split_date_test]['date'],\n",
    "            y=df[df['date']>=split_date_test][demand_column],\n",
    "            name = 'y_truth',\n",
    "            mode=\"lines+markers\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Display the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: highlight the last section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/image/sports.png\" width=900 height=900 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the forecast with event features againest that without event features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withoutevents = df[['date','demand','day_of_week','week_of_year','month_of_year']]\n",
    "df_withoutevents.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_withoutevents = df_withoutevents.columns[2:]\n",
    "X_train_withoutevents = df_withoutevents[df_withoutevents['date']<split_date_test][feature_columns_withoutevents]\n",
    "X_test_withoutevents = df_withoutevents[df_withoutevents['date']>=split_date_test][feature_columns_withoutevents]\n",
    "y_train_withoutevents = df_withoutevents[df_withoutevents['date']<split_date_test][demand_column]\n",
    "y_test_withoutevents = df_withoutevents[df_withoutevents['date']>=split_date_test][demand_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_withoutevents = XGBRegressor(n_estimators=100,\n",
    "                        learning_rate = .1,\n",
    "                        max_depth = 6,\n",
    "                        random_state=42,\n",
    "                        n_jobs = -1,\n",
    "                        )\n",
    "xgb_model_withoutevents.fit(X_train_withoutevents, \n",
    "                y_train_withoutevents,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x= df_withoutevents[df_withoutevents['date']<split_date_test]['date'],\n",
    "            y=df_withoutevents[df_withoutevents['date']<split_date_test][demand_column],\n",
    "            name = 'y_training',\n",
    "            mode=\"lines+markers\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x= df_withoutevents[df_withoutevents['date']>=split_date_test]['date'],\n",
    "            y=xgb_model_withoutevents.predict(X_test_withoutevents),\n",
    "            name = 'y_prediction_no_events',\n",
    "            mode=\"lines+markers\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x= df_withoutevents[df_withoutevents['date']>=split_date_test]['date'],\n",
    "            y=df_withoutevents[df_withoutevents['date']>=split_date_test][demand_column],\n",
    "            name = 'y_truth',\n",
    "            mode=\"lines+markers\",\n",
    "        )\n",
    "    )\n",
    "fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x= df[df['date']>=split_date_test]['date'],\n",
    "            y=xgb_model.predict(X_test),\n",
    "            name = 'y_prediction_withevents',\n",
    "            mode=\"lines+markers\",\n",
    "        )\n",
    "    )\n",
    "# Display the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison based on Mean Absolute Error (MAE) and Root Mean Square Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "MAE_model_withevents = mean_absolute_error(y_test, xgb_model.predict(X_test))\n",
    "MAE_model_no_events = mean_absolute_error(y_test_withoutevents, xgb_model_withoutevents.predict(X_test_withoutevents))\n",
    "MAE_Model_improvement = (MAE_model_no_events - MAE_model_withevents)/MAE_model_no_events *100\n",
    "\n",
    "RMSE_model_withevents = mean_squared_error(y_test, xgb_model.predict(X_test), squared=False)\n",
    "RMSE_model_no_events = mean_squared_error(y_test_withoutevents, xgb_model_withoutevents.predict(X_test_withoutevents), squared=False)\n",
    "RMSE_Model_improvement = (RMSE_model_no_events - RMSE_model_withevents)/RMSE_model_no_events *100\n",
    "\n",
    "print(f\"MAE for forecasting with events is {MAE_model_withevents:.2f}\")\n",
    "print(f\"MAE for forecasting without events is {MAE_model_no_events:.2f}\")\n",
    "print(f\"MAE improvement of having event features in a forecast model is {MAE_Model_improvement:.2f}%\")\n",
    "print(\" \")\n",
    "print(f\"RMSE for forecasting with events is {RMSE_model_withevents:.2f}\")\n",
    "print(f\"RMSE for forecasting without events is {RMSE_model_no_events:.2f}\")\n",
    "print(f\"RMSE improvement of having event features in a forecast model is {RMSE_Model_improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
